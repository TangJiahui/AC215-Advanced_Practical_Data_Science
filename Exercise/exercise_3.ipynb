{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "exercise_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfTh4bUzAmSX"
      },
      "source": [
        "<h1 style=\"padding-top: 25px;padding-bottom: 25px;text-align: left; padding-left: 10px; background-color: #DDDDDD; \n",
        "    color: black;\"> <img style=\"float: left; padding-right: 10px;\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\" height=\"50px\"> <a href='https://harvard-iacs.github.io/2021-AC215/' target='_blank'><strong><font color=\"#A41034\">AC215: Advanced Practical Data Science, MLOps</font></strong></a></h1>\n",
        "\n",
        "# **<font color=\"#A41034\">Exercise 3 - Mushroom Identification Models</font>**\n",
        "\n",
        "**Harvard University**<br/>\n",
        "**Fall 2021**<br/>\n",
        "**Instructor:**<br/>\n",
        "Pavlos Protopapas\n",
        "\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWSXnfQUStq5"
      },
      "source": [
        "## **<font color=\"#A41034\">Competition</font>**\n",
        "\n",
        "### **<font color=\"#f03b20\">Due Date: Check Canvas</font>**\n",
        "\n",
        "#### **[View Leaderboard](http://ac215-leaderboard.dlops.io/)**\n",
        "\n",
        "Now your task for this exercise is to build the best model for mushroom classification. You are free to use any techniques. Here are some techniques you can try:\n",
        "\n",
        "* Data augmentation\n",
        "* Hyper parameters tuning\n",
        "* Transfer Learning using different pre-trained models\n",
        "* Learning rate schedulers\n",
        "* Early stopping\n",
        "* etc...\n",
        "\n",
        "#### **Exercise Requirements:**\n",
        "* Create TF Records to build your data pipelines\n",
        "* Perform model compression using Distillation\n",
        "* Perform model compression using Pruning\n",
        "\n",
        "You can submit as many models as you want with any techniques used but make sure to keep your work based on the above requirements before you submit your notebook on canvas\n",
        "\n",
        "<br>\n",
        "\n",
        "**Remember to submit your experiments to the cloud storage bucket using the code provided and also submit your notebook to Canvas**\n",
        "\n",
        "<br>\n",
        "\n",
        "**<font color=\"#f03b20\">Leaderboard for this competition will be computed based on `hidden` test set. Winner gets a $50 Amazon gift card from Pavlos</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgY9xWhgGdt8"
      },
      "source": [
        "## **<font color=\"#A41034\">Setup Notebook</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-HGo-xOGr2t"
      },
      "source": [
        "**Copy & setup Colab with GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfXH3wYGtSa"
      },
      "source": [
        "1) Select \"File\" menu and pick \"Save a copy in Drive\"  \n",
        "2) This notebooks is already setup to use GPU but if you want to change it. Go to \"Runtime\" menu and select \"Change runtime type\". Then in the popup in \"Hardware accelerator\" select \"GPU\" and then click \"Save\"   \n",
        "3) If you want high RAM there is an option for that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsHQIdyQHAkV"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7OG0AQAlha"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import tarfile\n",
        "import shutil\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "import cv2\n",
        "import string\n",
        "import re\n",
        "import subprocess\n",
        "import hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import collections\n",
        "import unicodedata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils.layer_utils import count_params\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tensorflow Hub\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Colab auth\n",
        "from google.colab import auth\n",
        "from google.cloud import storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwwaaoEAMmLg"
      },
      "source": [
        "**Verify Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD106cXQMm_8"
      },
      "source": [
        "It is a good practice to verify what version of TensorFlow & Keras you are using. Also verify if GPU is enabled and what GPU you have. Run the following cells to check the version of TensorFlow\n",
        "\n",
        "References:\n",
        "- [Eager Execution](https://www.tensorflow.org/guide/eager)\n",
        "- [Data Performance](https://www.tensorflow.org/guide/data_performance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHjjqJjIMtFH"
      },
      "source": [
        "# Enable/Disable Eager Execution\n",
        "# Reference: https://www.tensorflow.org/guide/eager\n",
        "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
        "# without building graphs\n",
        "\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "print(\"tensorflow version\", tf.__version__)\n",
        "print(\"keras version\", tf.keras.__version__)\n",
        "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
        "\n",
        "# Get the number of replicas \n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "devices = tf.config.experimental.get_visible_devices()\n",
        "print(\"Devices:\", devices)\n",
        "print(tf.config.experimental.list_logical_devices('GPU'))\n",
        "\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
        "\n",
        "# Better performance with the tf.data API\n",
        "# Reference: https://www.tensorflow.org/guide/data_performance\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBRyDL1GMwj0"
      },
      "source": [
        "Run this cell to see what GPU you have. If you get a P100 or T4 GPU that's great. If it's K80, it will still work but it will be slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbysV9VCMxDy"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i3sZbohM2K_"
      },
      "source": [
        "**Utils**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIn5czLvM2sS"
      },
      "source": [
        "Here are some util functions that we will be using for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm_puO9WSoq3"
      },
      "source": [
        "def download_file(packet_url, base_path=\"\", extract=False, headers=None):\n",
        "  if base_path != \"\":\n",
        "    if not os.path.exists(base_path):\n",
        "      os.mkdir(base_path)\n",
        "  packet_file = os.path.basename(packet_url)\n",
        "  with requests.get(packet_url, stream=True, headers=headers) as r:\n",
        "      r.raise_for_status()\n",
        "      with open(os.path.join(base_path,packet_file), 'wb') as f:\n",
        "          for chunk in r.iter_content(chunk_size=8192):\n",
        "              f.write(chunk)\n",
        "  \n",
        "  if extract:\n",
        "    if packet_file.endswith(\".zip\"):\n",
        "      with zipfile.ZipFile(os.path.join(base_path,packet_file)) as zfile:\n",
        "        zfile.extractall(base_path)\n",
        "    else:\n",
        "      packet_name = packet_file.split('.')[0]\n",
        "      with tarfile.open(os.path.join(base_path,packet_file)) as tfile:\n",
        "        tfile.extractall(base_path)\n",
        "\n",
        "def compute_dataset_metrics(data_list):\n",
        "  data_list_with_metrics = []\n",
        "  for item in data_list:\n",
        "    # Read image\n",
        "    image = cv2.imread(item[1])\n",
        "    data_list_with_metrics.append((item[0],item[1],image.shape[0],image.shape[1],image.nbytes / (1024 * 1024.0)))\n",
        "\n",
        "  # Build a dataframe\n",
        "  data_list_with_metrics = np.asarray(data_list_with_metrics)\n",
        "  dataset_df = pd.DataFrame({\n",
        "    'label': data_list_with_metrics[:, 0], \n",
        "    'path': data_list_with_metrics[:, 1],\n",
        "    'height': data_list_with_metrics[:, 2],\n",
        "    'width': data_list_with_metrics[:, 3],\n",
        "    'size': data_list_with_metrics[:, 4],\n",
        "    })\n",
        "  \n",
        "  dataset_df[\"height\"] = dataset_df[\"height\"].astype(int)\n",
        "  dataset_df[\"width\"] = dataset_df[\"width\"].astype(int)\n",
        "  dataset_df[\"size\"] = dataset_df[\"size\"].astype(float)\n",
        "\n",
        "  dataset_mem_size = dataset_df[\"size\"].sum()\n",
        "  value_counts = dataset_df[\"label\"].value_counts()\n",
        "  height_details = dataset_df[\"height\"].describe()\n",
        "  width_details = dataset_df[\"width\"].describe()\n",
        "\n",
        "  print(\"Dataset Metrics:\")\n",
        "  print(\"----------------\")\n",
        "  print(\"Label Counts:\")\n",
        "  print(value_counts)\n",
        "  print(\"Image Width:\")\n",
        "  print(\"Min:\",width_details[\"min\"],\" Max:\",width_details[\"max\"])\n",
        "  print(\"Image Height:\")\n",
        "  print(\"Min:\",height_details[\"min\"],\" Max:\",height_details[\"max\"])\n",
        "  print(\"Size in memory:\",round(dataset_df[\"size\"].sum(),2),\"MB\")\n",
        "\n",
        "class JsonEncoder(json.JSONEncoder):\n",
        "  def default(self, obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, decimal.Decimal):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return super(JsonEncoder, self).default(obj)\n",
        "\n",
        "experiment_name = None\n",
        "def create_experiment():\n",
        "  global experiment_name\n",
        "  experiment_name = \"experiment_\" + str(int(time.time()))\n",
        "\n",
        "  # Create experiment folder\n",
        "  if not os.path.exists(experiment_name):\n",
        "      os.mkdir(experiment_name)\n",
        "\n",
        "def upload_experiment(data_details):\n",
        "  \n",
        "  # Check the logged in account\n",
        "  user_account = !gcloud config get-value account\n",
        "  user_account = user_account[0]\n",
        "  print(\"user_account\",user_account)\n",
        "\n",
        "  # Check Bucket Access\n",
        "  bucket_name = \"ac215-mushroom-app-models\" # BUCKET NAME\n",
        "\n",
        "  # List buckets in a GCP project\n",
        "  storage_client = storage.Client(project=\"ac215-project\") # PROJECT ID \n",
        "\n",
        "  # Get bucket for Experiments\n",
        "  bucket = storage_client.get_bucket(bucket_name)\n",
        "  print(\"Model Bucket:\",bucket)\n",
        "\n",
        "  # Save data details used for the experiment\n",
        "  save_data_details(data_details)\n",
        "\n",
        "  # Copy the experiment folder to GCP Bucket\n",
        "  for file_path in glob(experiment_name+'/*'):\n",
        "    print(file_path)\n",
        "    blob = bucket.blob(os.path.join(user_account,file_path)) \n",
        "    print('uploading file', file_path)\n",
        "    blob.upload_from_filename(file_path)\n",
        "  \n",
        "  # Submit file\n",
        "  submit_file = \"submit.txt\"\n",
        "  with open(submit_file, \"w\") as f:\n",
        "    f.write(\"Submission!\")\n",
        "\n",
        "  blob = bucket.blob(submit_file) \n",
        "  print('Uploading file', submit_file)\n",
        "  blob = bucket.blob(os.path.join(user_account,experiment_name,submit_file)) \n",
        "  blob.upload_from_filename(submit_file)\n",
        "\n",
        "def save_data_details(data_details):\n",
        "  with open(os.path.join(experiment_name,\"data_details.json\"), \"w\") as json_file:\n",
        "    json_file.write(json.dumps(data_details,cls=JsonEncoder))\n",
        "\n",
        "def save_model(model,model_name=\"model01\"):\n",
        "\n",
        "  # Save the enitire model (structure + weights)\n",
        "  model.save(os.path.join(experiment_name,model_name+\".hdf5\"))\n",
        "\n",
        "  # Save only the weights\n",
        "  model.save_weights(os.path.join(experiment_name,model_name+\".h5\"))\n",
        "\n",
        "  # Save the structure only\n",
        "  model_json = model.to_json()\n",
        "  with open(os.path.join(experiment_name,model_name+\".json\"), \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "\n",
        "def get_model_size(model_name=\"model01\"):\n",
        "  model_size = os.stat(os.path.join(experiment_name,model_name+\".h5\")).st_size\n",
        "  return model_size\n",
        "\n",
        "def append_training_history(model_train_history, prev_model_train_history):\n",
        "  for metric in [\"loss\",\"val_loss\",\"accuracy\",\"val_accuracy\"]:\n",
        "    for metric_value in prev_model_train_history[metric]:\n",
        "      model_train_history[metric].append(metric_value)\n",
        "  \n",
        "  return model_train_history\n",
        "\n",
        "def evaluate_save_model(model,test_data, model_train_history,execution_time, learning_rate, batch_size, epochs, optimizer,save=True):\n",
        "  \n",
        "  # Get the number of epochs the training was run for\n",
        "  num_epochs = len(model_train_history[\"loss\"])\n",
        "\n",
        "  # Plot training results\n",
        "  fig = plt.figure(figsize=(15,5))\n",
        "  axs = fig.add_subplot(1,2,1)\n",
        "  axs.set_title('Loss')\n",
        "  # Plot all metrics\n",
        "  for metric in [\"loss\",\"val_loss\"]:\n",
        "      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n",
        "  axs.legend()\n",
        "  \n",
        "  axs = fig.add_subplot(1,2,2)\n",
        "  axs.set_title('Accuracy')\n",
        "  # Plot all metrics\n",
        "  for metric in [\"accuracy\",\"val_accuracy\"]:\n",
        "      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n",
        "  axs.legend()\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  # Evaluate on test data\n",
        "  evaluation_results = model.evaluate(test_data)\n",
        "  print(evaluation_results)\n",
        "  \n",
        "  if save:\n",
        "    # Save model\n",
        "    save_model(model, model_name=model.name)\n",
        "    model_size = get_model_size(model_name=model.name)\n",
        "\n",
        "    # Save model history\n",
        "    with open(os.path.join(experiment_name,model.name+\"_train_history.json\"), \"w\") as json_file:\n",
        "        json_file.write(json.dumps(model_train_history,cls=JsonEncoder))\n",
        "\n",
        "    trainable_parameters = count_params(model.trainable_weights)\n",
        "    non_trainable_parameters = count_params(model.non_trainable_weights)\n",
        "\n",
        "    # Save model metrics\n",
        "    metrics ={\n",
        "        \"trainable_parameters\":trainable_parameters,\n",
        "        \"execution_time\":execution_time,\n",
        "        \"loss\":evaluation_results[0],\n",
        "        \"accuracy\":evaluation_results[1],\n",
        "        \"model_size\":model_size,\n",
        "        \"learning_rate\":learning_rate,\n",
        "        \"batch_size\":batch_size,\n",
        "        \"epochs\":epochs,\n",
        "        \"optimizer\":type(optimizer).__name__\n",
        "    }\n",
        "    with open(os.path.join(experiment_name,model.name+\"_model_metrics.json\"), \"w\") as json_file:\n",
        "        json_file.write(json.dumps(metrics,cls=JsonEncoder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1BzqnfOVwuk"
      },
      "source": [
        "## **<font color=\"#A41034\">Dataset</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9hohypOVzX2"
      },
      "source": [
        "#### **Download**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZP5r9sAVzvx"
      },
      "source": [
        "start_time = time.time()\n",
        "download_file(\"https://github.com/dlops-io/datasets/releases/download/v1.0/mushrooms_6_labels.zip\", base_path=\"datasets\", extract=True)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Download execution time (mins)\",execution_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhtRhKfV_8k"
      },
      "source": [
        "#### **Load & EDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bxevi-PWB_U"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AFAkCSbWGpk"
      },
      "source": [
        "## **<font color=\"#A41034\">Build Data Pipelines</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0FGp87kWQva"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoSaYFL7WVeS"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eJGLU8MWQ_k"
      },
      "source": [
        "## **<font color=\"#A41034\">Build Image Classificaton Models</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyOyZHlcWTmd"
      },
      "source": [
        "### **Create Experiment**\n",
        "\n",
        "Use the util functions to create an experiment to keep track of hyper parameters, metrics, models etc. This will be used for your submission to the cloud storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0e1xIWNWoed"
      },
      "source": [
        "# Create an experiment\n",
        "create_experiment()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtRZ1NOWrlX"
      },
      "source": [
        "### **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRHjRhgKWU0u"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWUcehi3WwTW"
      },
      "source": [
        "### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwNjxJFzWyaA"
      },
      "source": [
        "# Your code here\n",
        "\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model.fit(\n",
        "        train_data,\n",
        "        validation_data=validation_data,\n",
        "        epochs=epochs,\n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)\n",
        "\n",
        "####################################\n",
        "##### Use this code to Save ########\n",
        "####################################\n",
        "# Get model training history\n",
        "training_history = training_results.history\n",
        "# Evaluate and save the model details\n",
        "evaluate_save_model(model,test_data, training_history,execution_time, learning_rate, batch_size, epochs, optimizer,save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gJ1XFU1XLTe"
      },
      "source": [
        "## **<font color=\"#A41034\">Experiment Results</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KacYD5GXOAI"
      },
      "source": [
        "#### **Compare Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKqeVCdSXQA5"
      },
      "source": [
        "models_metrics_list = glob(experiment_name+\"/*_model_metrics.json\")\n",
        "\n",
        "all_models_metrics = []\n",
        "for mm_file in models_metrics_list:\n",
        "  with open(mm_file) as json_file:\n",
        "    model_metrics = json.load(json_file)\n",
        "    model_metrics[\"name\"] = mm_file.replace(experiment_name+\"/\",\"\").replace(\"_model_metrics.json\",\"\")\n",
        "    all_models_metrics.append(model_metrics)\n",
        "\n",
        "# Load metrics to dataframe\n",
        "view_metrics = pd.DataFrame(data=all_models_metrics)\n",
        "\n",
        "# Format columns\n",
        "view_metrics['accuracy'] = view_metrics['accuracy']*100\n",
        "view_metrics['accuracy'] = view_metrics['accuracy'].map('{:,.2f}%'.format)\n",
        "\n",
        "view_metrics['trainable_parameters'] = view_metrics['trainable_parameters'].map('{:,.0f}'.format)\n",
        "view_metrics['execution_time'] = view_metrics['execution_time'].map('{:,.2f} mins'.format)\n",
        "view_metrics['loss'] = view_metrics['loss'].map('{:,.2f}'.format)\n",
        "view_metrics['model_size'] = view_metrics['model_size']/1000000\n",
        "view_metrics['model_size'] = view_metrics['model_size'].map('{:,.0f} MB'.format)\n",
        "\n",
        "view_metrics = view_metrics.sort_values(by=['accuracy'],ascending=False)\n",
        "view_metrics.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDHkyTPmXXTD"
      },
      "source": [
        "## **<font color=\"#A41034\">Upload Experiment to Cloud Storage</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWyT7IxWXX5D"
      },
      "source": [
        "### **Login using Google Acccount**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4mJehNYXc8t"
      },
      "source": [
        "# Authenticate\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poph_6TLXmfT"
      },
      "source": [
        "### **Save Experiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBC3VWnSXnG2"
      },
      "source": [
        "# Save data details used for the experiment\n",
        "data_details = {\n",
        "  \"image_width\": image_width,\n",
        "  \"image_height\": image_height,\n",
        "  \"num_channels\": num_channels,\n",
        "  \"num_classes\": num_classes,\n",
        "  \"label2index\": label2index,\n",
        "  \"index2label\": index2label\n",
        "}\n",
        "\n",
        "# Upload experiment to cloud storage\n",
        "upload_experiment(data_details)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}